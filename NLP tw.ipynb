{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151eb5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from lib.download import *\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import snscrape.modules.twitter as sntwitter\n",
    "import pandas as pd\n",
    "import time\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "from selenium.webdriver.common.desired_capabilities import DesiredCapabilities\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "import concurrent.futures\n",
    "import queue\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, BertTokenizer, BertForSequenceClassification, pipeline\n",
    "from scipy.special import expit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed536d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the tokenizer and model\n",
    "topictokenizer = AutoTokenizer.from_pretrained(\"cardiffnlp/tweet-topic-21-multi\")\n",
    "topicmodel = AutoModelForSequenceClassification.from_pretrained(\"cardiffnlp/tweet-topic-21-multi\")\n",
    "topic_mapping = topicmodel.config.id2label # Links between predicted classes and corresponding topics\n",
    "topicmodel.to(device)  # CUDA\n",
    "\n",
    "###FLS\n",
    "flsmodel = BertForSequenceClassification.from_pretrained('yiyanghkust/finbert-fls',num_labels=3)\n",
    "flstokenizer = BertTokenizer.from_pretrained('yiyanghkust/finbert-fls')\n",
    "nlp = pipeline(\"text-classification\", model=flsmodel, tokenizer=flstokenizer)\n",
    "flsmodel.to(device)  # CUDA\n",
    "\n",
    "def pred_topic(tweet):\n",
    "    inputs = topictokenizer(tweet, return_tensors=\"pt\")\n",
    "    outputs = topicmodel(**inputs)\n",
    "    scores = outputs[0][0].detach().numpy()\n",
    "    scores = expit(scores)\n",
    "    predictions = (scores >= 0.5) * 1                                    \n",
    "    return [topic_mapping[predictions.argmax()]]\n",
    "\n",
    "def pred_fls(tweet):  \n",
    "    return list(nlp(tweet)[0].values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867c551f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918acd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### retrieve preselected twitter usernames ####\n",
    "\n",
    "user_list = pd.read_excel('data/tweets/usernames.xlsx')['Usernames'].tolist()\n",
    "user_list = [user.lstrip() for user in user_list]\n",
    "\n",
    "df = pd.read_csv(f'data/tweets/{\"@BTC_Archive\"}.csv')\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe49b410",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5020aba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305c2710",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_tweet_db_attributes(username_list):\n",
    "    for user in user_list:\n",
    "        attributes = []\n",
    "        tweets = pd.read_csv(f'data/tweets/{user}.csv')\n",
    "        for tweet in tqdm(df[\"Tweet\"]):\n",
    "            attributes.append(pred_topic(tweet)+pred_fls(tweet))\n",
    "        attributes_df = pd.DataFrame(attributes,columns=['topic','fls','fls_score'])\n",
    "        pd.concat([tweets,attributes_df], axis=1).to_csv(f'data/tweets/{user}_attributes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a6e83d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.read_csv('data/tweets/@elonmusk_attributes.csv').iloc[:,3:].to_excel('exmple.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8d64c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_tweet_db_attributes(user_list[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a886bd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoformer  tres bonnes performances et comprehensible aussi\n",
    "sionon timesnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a53245",
   "metadata": {},
   "outputs": [],
   "source": [
    "avantage tft est quantiles pr stoploss + machineln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0882aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hourly_summarizer()\n",
    "gpt? fichier brut = > output direct par  heure voir colab gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08633818",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweet_context-\n",
    "avec gpt aussi, dire neutre si pas assez a summarize, volir ds sntweeter por la cconv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d29139",
   "metadata": {},
   "outputs": [],
   "source": [
    "peut meme aller encore plus loin en demandant tout a chatgpt en une fois (fls...............)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953638ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "get  attributes sur le summarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddfa0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "backtrader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33829a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca pr analyse des tweets les mieux\n",
    "\n",
    "dans un premier temps nelever tous les arobases\n",
    "\n",
    "bcp de tweets sont analyséssans contexte (reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139709e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "faire la pred sur le sommaire horaire par user et par  crypto?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d4247f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model positive neut neg puissant\n",
    "https://huggingface.co/oferweintraub/bert-base-finance-sentiment-noisy-search?text=Microsoft+updates+Outlook%2C+Teams%2C+and+PowerPoint+to+be+hybrid+work+ready\n",
    "\n",
    "autre candidat\n",
    "https://huggingface.co/nickmuchi/deberta-v3-base-finetuned-finance-text-classification?text=the+USD+has+been+trending+lower\n",
    "    \n",
    "    \n",
    "classif pr comprendre quelle crypto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfc99ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "label huge volat predicted avec un bert custom\n",
    "\n",
    "trouver les crypto de predilection de chaque utilisateur / eliminer ceux qui ont trop peu d'info/ faire la classif dxe topic pr filtrer et reeliminer ceux qui parlent trop pr rien par ex\n",
    "\n",
    "predire plusieurs classes => court terme : positif et long terme : negatif (juste variable : court terme / long terme / moyen terme manuellement)\n",
    "        \n",
    "crypto twitter account recommendation algorithm\n",
    "\n",
    "filtrer par secteur finance\n",
    "\n",
    "predire avec bert => acheter levier, spot......\n",
    "\n",
    "faire dashboard backtest stylé : https://huggingface.co/nickmuchi/finbert-tone-finetuned-finance-topic-classification?text=Company+and+Elon+Musk+are+set+for+a+blockbuster+courtroom+battle+over+Musk%E2%80%99s+attempt+to+terminate+his+%2444+billion+acquisition+deal+for+%24TWTR%2C+according+to+Wedbush+analyst+Dan+Ives.\n",
    "\n",
    "classifieur de qualités d'une personne => non related , futures , ETHn mec chaud mec nul\n",
    "\n",
    "#pr less comptes bien connus on va chercher a avoir des signaux constant (pearson haut avec y), pr les moins connus, on va évaluer leur capacité a prédire des mouvements tres volatiles \n",
    "si utilisation de crypto bert, bien filtrer avant les tweets car le fine tuning a étz effectué sur des tweets uniquement\n",
    "\n",
    "features comme vues des tweets pas importants car stockes seulmement une fois fini or on veut une estimation des la publication du sentiment créé et sentiment créable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba8bb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "voir recommandation apres\n",
    "donner plus dimportance aux scores de tweet de fin  d'heure comparée au début lors du groupy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5341ea60",
   "metadata": {},
   "outputs": [],
   "source": [
    "reccommandation crypto n,ested fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ed26c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### finance topic clasisification ####\n",
    "\n",
    "topics = [\"Analyst Update\",\"Fed | Central Banks\",\"Company | Product News\",\"Treasuries | Corporate Debt\",\"Dividend\",\"Earnings\",\"Energy | Oil\",\"Financials\",\"Currencies\",\"General News | Opinion\",\"Gold | Metals | Materials\",\"IPO\",\"Legal | Regulation\",\"M&A | Investments\",\"Macro\",\"Markets\",\"Politics\",\"Personnel Change\",\"Stock Commentary\",\"Stock Movement\",]\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"nickmuchi/finbert-tone-finetuned-finance-topic-classification\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"nickmuchi/finbert-tone-finetuned-finance-topic-classification\")\n",
    "model.to(device)  # Enable CUDA\n",
    "\n",
    "def pred_topic(tweet):\n",
    "    inputs = tokenizer(tweet, return_tensors=\"pt\")\n",
    "    outputs = model(**inputs)\n",
    "    probs = F.softmax(outputs.logits, dim=1)\n",
    "    return pd.DataFrame(probs.detach().numpy(), columns=topics,index = ['probs']).sort_values(by=['probs'],ascending=False, axis=1)\n",
    "\n",
    "def get_max_column_names(df):\n",
    "    return df.apply(lambda x: x.idxmax(), axis=1).reset_index(drop=True)\n",
    "\n",
    "res = pd.concat([df.iloc[:,1:],get_max_column_names(res)],axis=1)\n",
    "res.columns = ['Date','User','Tweet','Topic']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
