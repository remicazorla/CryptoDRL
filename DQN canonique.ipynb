{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19d325bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensortrade.env.default as default\n",
    "from tensortrade.oms.exchanges import Exchange\n",
    "from tensortrade.feed import Stream\n",
    "from tensortrade.oms.services.execution.simulated import execute_order\n",
    "from tensortrade.feed.core import Stream, DataFeed, NameSpace\n",
    "from tensortrade.oms.wallets import Wallet, Portfolio\n",
    "from tensortrade.oms.instruments import Instrument\n",
    "from tensortrade.agents import DQNAgent, ParallelDQNAgent\n",
    "from tensortrade.env.default.actions import BSH, ManagedRiskOrders\n",
    "from tensortrade.env.default.rewards import RiskAdjustedReturns, PBR, SimpleProfit\n",
    "from tensortrade.env.default.renderers import PlotlyTradingChart\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import multiprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.options.mode.use_inf_as_na = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97f9c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling des features pouvant etre important => robust scaler\n",
    "fracdiff\n",
    "deflated sharpe ratio\n",
    "modele a l'air tres puisaste\n",
    "https://github.com/zoakes/RL/blob/master/RI_ML.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ecdcebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_df(df, n_components):\n",
    "    pca = PCA(n_components = n_components)\n",
    "    pca.fit(df)\n",
    "    eig_val, eig_ratio = pca.explained_variance_, pca.explained_variance_ratio_ \n",
    "    df_pca = pd.DataFrame(pca.transform(df), index =df.index)\n",
    "    df_pca.columns = [f\"PC{i+1}\" for i in range(n_components)]\n",
    "    print(f\"Keyser : {len(eig_val[eig_val > 1])}, Actual E.V. ratio : {np.round(eig_ratio.cumsum()[-1:][0]*100,2)}\")\n",
    "    return df_pca "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa89c3ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max first date : 2020-09-01 02:00:00 max last date : 2023-01-30 17:00:00\n",
      "dropped: ['tb_quote_av', 'sma5', 'ema8', 'sma8', 'ema12', 'sma12', 'ema16', 'sma16', 'ema20', 'sma20', 'ema26', 'sma26', 'rsi10', 'rsi14', 'adx17', 'rsi17', 'willR17', 'cci17', 'adx20', 'rsi20', 'stochrsi20', 'willR20', 'cci20', 'adx25', 'rsi25', 'willR25', 'cci25', 'volume_vwap', 'volatility_bbh', 'volatility_bbl', 'volatility_bbp', 'volatility_kcc', 'volatility_kch', 'volatility_kcl', 'volatility_dcl', 'volatility_dch', 'volatility_dcm', 'volatility_dcp', 'trend_macd_signal', 'trend_vortex_ind_diff', 'trend_kst_sig', 'trend_ichimoku_conv', 'trend_ichimoku_base', 'trend_ichimoku_a', 'trend_ichimoku_b', 'trend_visual_ichimoku_a', 'trend_visual_ichimoku_b', 'momentum_stoch', 'momentum_ao', 'momentum_ppo_signal', 'momentum_kama', 'alpha6', 'alpha51']\n",
      "dropped: ['tb_quote_av', 'sma5', 'ema8', 'sma8', 'ema12', 'sma12', 'ema16', 'sma16', 'ema20', 'sma20', 'ema26', 'sma26', 'rsi10', 'rsi14', 'adx17', 'rsi17', 'willR17', 'cci17', 'adx20', 'rsi20', 'stochrsi20', 'willR20', 'cci20', 'adx25', 'rsi25', 'willR25', 'cci25', 'volume_obv', 'volume_vwap', 'volatility_bbh', 'volatility_bbl', 'volatility_bbp', 'volatility_kcc', 'volatility_kch', 'volatility_kcl', 'volatility_dcl', 'volatility_dch', 'volatility_dcm', 'volatility_dcp', 'trend_macd_signal', 'trend_vortex_ind_diff', 'trend_kst_sig', 'trend_ichimoku_conv', 'trend_ichimoku_base', 'trend_ichimoku_a', 'trend_ichimoku_b', 'trend_visual_ichimoku_a', 'trend_visual_ichimoku_b', 'momentum_stoch', 'momentum_ao', 'momentum_ppo_signal', 'momentum_kama', 'alpha6', 'alpha51']\n",
      "dropped: ['tb_quote_av', 'sma5', 'ema8', 'sma8', 'ema12', 'sma12', 'ema16', 'sma16', 'ema20', 'sma20', 'ema26', 'sma26', 'rsi10', 'rsi14', 'adx17', 'rsi17', 'willR17', 'cci17', 'adx20', 'rsi20', 'stochrsi20', 'willR20', 'cci20', 'adx25', 'rsi25', 'willR25', 'cci25', 'volume_obv', 'volume_vwap', 'volatility_bbh', 'volatility_bbl', 'volatility_bbp', 'volatility_kcc', 'volatility_kch', 'volatility_kcl', 'volatility_dcl', 'volatility_dch', 'volatility_dcm', 'volatility_dcp', 'trend_macd_signal', 'trend_vortex_ind_diff', 'trend_kst_sig', 'trend_ichimoku_conv', 'trend_ichimoku_base', 'trend_ichimoku_a', 'trend_ichimoku_b', 'trend_visual_ichimoku_a', 'trend_visual_ichimoku_b', 'momentum_stoch', 'momentum_ao', 'momentum_ppo_signal', 'momentum_kama', 'others_cr', 'alpha6', 'alpha51']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def load_ticker_data(tickers, drop_first_nrows=500):\n",
    "    env_data = []\n",
    "    first_dates = []\n",
    "    last_dates = []\n",
    "    for ticker in tickers:\n",
    "        data = pd.read_pickle(f'data/usdt_data_features/{ticker}.pickle').astype(float)\n",
    "        if drop_first_nrows != 0:\n",
    "            data = data.iloc[drop_first_nrows:, :]\n",
    "        env_data.append(data)\n",
    "        first_dates.append(data.index[0]) \n",
    "        last_dates.append(data.index[-1])\n",
    "\n",
    "    max_first_date = max(first_dates)\n",
    "    min_last_date = min(last_dates)\n",
    "    env_data = [data.loc[(data.index >= max_first_date) & (data.index <= min_last_date)].bfill().ffill() for data in env_data]\n",
    "\n",
    "    print(f'max first date : {max_first_date} max last date : {min_last_date}')\n",
    "    return env_data\n",
    "\n",
    "\n",
    "def clean_data(stocks_data):\n",
    "    cleaned_data = []\n",
    "    for stock_data in stocks_data:\n",
    "        filtered_data = stock_data.copy().drop(columns=['open', 'high', 'low', 'close', 'volume','returns'])\n",
    "        corr_matrix = filtered_data.corr()\n",
    "        upperMatrix = corr_matrix.where(np.triu(np.ones(corr_matrix.shape, dtype=bool), k=1))\n",
    "        corrFeatures = [column for column in upperMatrix.columns if any(upperMatrix[column] > 0.95)]\n",
    "        print(f'dropped: {corrFeatures}')\n",
    "        cleaned_data.append(pd.concat([filtered_data.drop(columns=corrFeatures),stock_data[['open', 'high', 'low', 'close', 'volume','returns']]],axis=1))\n",
    "    return cleaned_data\n",
    "\n",
    "def split_data(data_list, train_sz=0.8, test_sz=0.2):\n",
    "    X_train_list, X_test_list, X_valid_list = [], [], []\n",
    "    y_train_list, y_test_list, y_valid_list = [], [], []\n",
    "\n",
    "    for data in data_list:\n",
    "        X = data.copy().drop(columns=['returns'])\n",
    "        y = data.copy()['returns']\n",
    "\n",
    "        X_train_test, X_valid, y_train_test, y_valid = train_test_split(X, y, train_size=train_sz, test_size=test_sz, shuffle=False)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_train_test, y_train_test, train_size=train_sz, test_size=test_sz, shuffle=False)\n",
    "\n",
    "        X_train_list.append(X_train)\n",
    "        X_test_list.append(X_test)\n",
    "        X_valid_list.append(X_valid)\n",
    "        y_train_list.append(y_train)\n",
    "        y_test_list.append(y_test)\n",
    "        y_valid_list.append(y_valid)\n",
    "\n",
    "    return X_train_list, X_test_list, X_valid_list, y_train_list, y_test_list, y_valid_list\n",
    "\n",
    "def separate_render_features(stocks_data, tickers):\n",
    "    ohlc_list, features_scaled_list = [], []\n",
    "    i=0\n",
    "    for stock_data in stocks_data:\n",
    "        ticker = tickers[i]\n",
    "        #ohlc prices for render\n",
    "        stock_ohlc = stock_data[['open','high','low','close','volume']].copy()\n",
    "        stock_ohlc['date'] = stock_ohlc.index\n",
    "        stock_ohlc = stock_ohlc.add_prefix(f\"{ticker}:\")\n",
    "        ohlc_list.append(stock_ohlc)\n",
    "\n",
    "        #all features to train from + scaling\n",
    "        scaler = StandardScaler()\n",
    "        stock_features = stock_data.copy()\n",
    "        stock_features = stock_features.add_prefix(f\"{ticker}:\")\n",
    "        scaler.fit(stock_features)\n",
    "        stock_features_scaled = pd.DataFrame(scaler.fit_transform(stock_features), columns = stock_features.columns, index = stock_features.index)\n",
    "        features_scaled_list.append(stock_features_scaled)\n",
    "        i+=1\n",
    "\n",
    "    return ohlc_list, features_scaled_list\n",
    "\n",
    "def get_price_stream(stock_renders, tickers):\n",
    "    stock_price_stream_list = []\n",
    "    \n",
    "    for i in range(len(stock_renders)):\n",
    "        stock_price_stream_list.append(Stream.source(list(stock_renders[i][f\"{tickers[i]}:close\"]), dtype=\"float\").rename(f\"USDT-{tickers[i]}\"))\n",
    "    return stock_price_stream_list\n",
    "\n",
    "def create_data_feed(features, use_pca):\n",
    "    all_scaled_features = pd.concat(features, axis=1)\n",
    "    if use_pca : \n",
    "        all_scaled_features = pca_df(all_scaled_features,100)\n",
    "    with NameSpace(\"binance\"):\n",
    "        features = [Stream.source(list(all_scaled_features[feature]), dtype=\"float\").rename(feature) for feature in all_scaled_features.columns]\n",
    "    all_features_feed = DataFeed(features)\n",
    "    all_features_feed.compile()\n",
    "    return all_features_feed\n",
    "\n",
    "def create_portfolio(tickers, currency = \"USDT\"):\n",
    "    instruments = {}\n",
    "    wallets = {}\n",
    "    for ticker in tickers:\n",
    "        instruments[ticker] = Instrument(ticker, 8, ticker)\n",
    "        wallets[ticker] = Wallet(binance, 0 * instruments[ticker])\n",
    "    usdt = Instrument(currency, 8, currency)\n",
    "    wallets['cash'] = Wallet(binance, 10000 * usdt) \n",
    "    portfolio_assets = [wallets['cash']] + [wallets[ticker] for ticker in tickers if ticker != 'USDT']\n",
    "    return Portfolio(usdt, portfolio_assets)\n",
    "\n",
    "tickers = [\"BTCUSDT\",\"ETHUSDT\",\"SOLUSDT\"]\n",
    "env_data = load_ticker_data(tickers)\n",
    "cleaned_data = clean_data(env_data)\n",
    "X_train_list, X_test_list, X_valid_list, y_train_list, y_test_list, y_valid_list = split_data(cleaned_data)\n",
    "renders, features = separate_render_features(X_test_list, tickers)\n",
    "price_streams = get_price_stream(renders, tickers)\n",
    "binance = Exchange('binance', service=execute_order)(*price_streams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "460ce8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "binance.options.commission = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "267371b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyser : 59, Actual E.V. ratio : 91.77\n"
     ]
    }
   ],
   "source": [
    "all_features_feed = create_data_feed(features, True)\n",
    "portfolio = create_portfolio(tickers,'USDT')\n",
    "\n",
    "#winsz a modif ici aussi (winsz du sortino?)\n",
    "reward_scheme = RiskAdjustedReturns(return_algorithm='sortino', window_size=24)\n",
    "action_scheme = ManagedRiskOrders(\n",
    "        #durations=[6],\n",
    "        stop=[0.005, 0.01, 0.03], \n",
    "        take=[0.005, 0.01, 0.03],\n",
    "        trade_sizes = [1/20, 1/10, 1/5, 1/2, 1]\n",
    ")\n",
    "\n",
    "#prediction du stoploss\n",
    "\n",
    "chart_renderer = PlotlyTradingChart(\n",
    "    display=True,\n",
    "    height=800,\n",
    "    save_format=\"html\",\n",
    "    auto_open_html=True,\n",
    ")\n",
    "    \n",
    "renderer_feed = DataFeed([\n",
    "    Stream.source(list(renders[0][\"BTCUSDT:date\"])).rename(\"date\"),\n",
    "    Stream.source(list(renders[0][\"BTCUSDT:open\"]), dtype=\"float\").rename(\"open\"),\n",
    "    Stream.source(list(renders[0][\"BTCUSDT:high\"]), dtype=\"float\").rename(\"high\"),\n",
    "    Stream.source(list(renders[0][\"BTCUSDT:low\"]), dtype=\"float\").rename(\"low\"),\n",
    "    Stream.source(list(renders[0][\"BTCUSDT:close\"]), dtype=\"float\").rename(\"close\"), \n",
    "    Stream.source(list(renders[0][\"BTCUSDT:volume\"]), dtype=\"float\").rename(\"volume\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd03da6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 24 #mieux que 48 d'zépres tests)\n",
    "env = default.create(\n",
    "    portfolio=portfolio,\n",
    "    action_scheme=action_scheme,\n",
    "    reward_scheme=reward_scheme,\n",
    "    feed=all_features_feed,\n",
    "    renderer_feed=renderer_feed,\n",
    "    renderer=chart_renderer,\n",
    "    window_size=window_size, #24\n",
    "    max_allowed_loss=0.3\n",
    ")\n",
    "\n",
    "#learning rate a 8e-6 sur un notebook (ppo)\n",
    "\n",
    "n_steps=5000\n",
    "memory_capacity = n_steps * 10\n",
    "\n",
    "seed = 1337\n",
    "commission = 0.0001\n",
    "\n",
    "save_path = 'agents/'\n",
    "\n",
    "agent = DQNAgent(env)\n",
    "\n",
    "agent.train(batch_size=64, \n",
    "            n_steps=n_steps, \n",
    "            n_episodes=25, \n",
    "            memory_capacity=memory_capacity, \n",
    "            save_path=save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da425e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def save_data_list(data_list, name, tickers):\n",
    "    with open(f'{name}_{\"_\".join(tickers)}.pickle', 'wb') as f:\n",
    "        pickle.dump(data_list, f)\n",
    "\n",
    "def preprocess_data(tickers):\n",
    "    env_data = load_ticker_data(tickers)\n",
    "    cleaned_data = clean_data(env_data)\n",
    "    X_train_list, X_test_list, X_valid_list, y_train_list, y_test_list, y_valid_list = split_data(cleaned_data)\n",
    "    data_splits = [(\"train\", X_train_list), (\"test\", X_test_list), (\"valid\", X_valid_list)]\n",
    "    renders, features = {}, {}\n",
    "    \n",
    "    for name, split in data_splits:\n",
    "        renders[name], features[name] = separate_render_features(split, tickers)\n",
    "        \n",
    "    for name in [\"train\", \"test\", \"valid\"]:\n",
    "        save_data_list(renders[name], f'{name}_renders', tickers)\n",
    "        save_data_list(features[name], f'{name}_features', tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c5abc040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max first date : 2020-09-01 02:00:00 max last date : 2023-01-30 17:00:00\n",
      "dropped: ['tb_quote_av', 'sma5', 'ema8', 'sma8', 'ema12', 'sma12', 'ema16', 'sma16', 'ema20', 'sma20', 'ema26', 'sma26', 'rsi10', 'rsi14', 'adx17', 'rsi17', 'willR17', 'cci17', 'adx20', 'rsi20', 'stochrsi20', 'willR20', 'cci20', 'adx25', 'rsi25', 'willR25', 'cci25', 'volume_vwap', 'volatility_bbh', 'volatility_bbl', 'volatility_bbp', 'volatility_kcc', 'volatility_kch', 'volatility_kcl', 'volatility_dcl', 'volatility_dch', 'volatility_dcm', 'volatility_dcp', 'trend_macd_signal', 'trend_vortex_ind_diff', 'trend_kst_sig', 'trend_ichimoku_conv', 'trend_ichimoku_base', 'trend_ichimoku_a', 'trend_ichimoku_b', 'trend_visual_ichimoku_a', 'trend_visual_ichimoku_b', 'momentum_stoch', 'momentum_ao', 'momentum_ppo_signal', 'momentum_kama', 'alpha6', 'alpha51']\n",
      "dropped: ['tb_quote_av', 'sma5', 'ema8', 'sma8', 'ema12', 'sma12', 'ema16', 'sma16', 'ema20', 'sma20', 'ema26', 'sma26', 'rsi10', 'rsi14', 'adx17', 'rsi17', 'willR17', 'cci17', 'adx20', 'rsi20', 'stochrsi20', 'willR20', 'cci20', 'adx25', 'rsi25', 'willR25', 'cci25', 'volume_obv', 'volume_vwap', 'volatility_bbh', 'volatility_bbl', 'volatility_bbp', 'volatility_kcc', 'volatility_kch', 'volatility_kcl', 'volatility_dcl', 'volatility_dch', 'volatility_dcm', 'volatility_dcp', 'trend_macd_signal', 'trend_vortex_ind_diff', 'trend_kst_sig', 'trend_ichimoku_conv', 'trend_ichimoku_base', 'trend_ichimoku_a', 'trend_ichimoku_b', 'trend_visual_ichimoku_a', 'trend_visual_ichimoku_b', 'momentum_stoch', 'momentum_ao', 'momentum_ppo_signal', 'momentum_kama', 'alpha6', 'alpha51']\n",
      "dropped: ['tb_quote_av', 'sma5', 'ema8', 'sma8', 'ema12', 'sma12', 'ema16', 'sma16', 'ema20', 'sma20', 'ema26', 'sma26', 'rsi10', 'rsi14', 'adx17', 'rsi17', 'willR17', 'cci17', 'adx20', 'rsi20', 'stochrsi20', 'willR20', 'cci20', 'adx25', 'rsi25', 'willR25', 'cci25', 'volume_obv', 'volume_vwap', 'volatility_bbh', 'volatility_bbl', 'volatility_bbp', 'volatility_kcc', 'volatility_kch', 'volatility_kcl', 'volatility_dcl', 'volatility_dch', 'volatility_dcm', 'volatility_dcp', 'trend_macd_signal', 'trend_vortex_ind_diff', 'trend_kst_sig', 'trend_ichimoku_conv', 'trend_ichimoku_base', 'trend_ichimoku_a', 'trend_ichimoku_b', 'trend_visual_ichimoku_a', 'trend_visual_ichimoku_b', 'momentum_stoch', 'momentum_ao', 'momentum_ppo_signal', 'momentum_kama', 'others_cr', 'alpha6', 'alpha51']\n"
     ]
    }
   ],
   "source": [
    "preprocess_data(tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74b6f991",
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = [\"BTCUSDT\",\"ETHUSDT\",\"SOLUSDT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6c43119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max first date : 2020-09-01 02:00:00 max last date : 2023-01-30 17:00:00\n",
      "dropped: ['tb_quote_av', 'sma5', 'ema8', 'sma8', 'ema12', 'sma12', 'ema16', 'sma16', 'ema20', 'sma20', 'ema26', 'sma26', 'rsi10', 'rsi14', 'adx17', 'rsi17', 'willR17', 'cci17', 'adx20', 'rsi20', 'stochrsi20', 'willR20', 'cci20', 'adx25', 'rsi25', 'willR25', 'cci25', 'volume_vwap', 'volatility_bbh', 'volatility_bbl', 'volatility_bbp', 'volatility_kcc', 'volatility_kch', 'volatility_kcl', 'volatility_dcl', 'volatility_dch', 'volatility_dcm', 'volatility_dcp', 'trend_macd_signal', 'trend_vortex_ind_diff', 'trend_kst_sig', 'trend_ichimoku_conv', 'trend_ichimoku_base', 'trend_ichimoku_a', 'trend_ichimoku_b', 'trend_visual_ichimoku_a', 'trend_visual_ichimoku_b', 'momentum_stoch', 'momentum_ao', 'momentum_ppo_signal', 'momentum_kama', 'alpha6', 'alpha51']\n",
      "dropped: ['tb_quote_av', 'sma5', 'ema8', 'sma8', 'ema12', 'sma12', 'ema16', 'sma16', 'ema20', 'sma20', 'ema26', 'sma26', 'rsi10', 'rsi14', 'adx17', 'rsi17', 'willR17', 'cci17', 'adx20', 'rsi20', 'stochrsi20', 'willR20', 'cci20', 'adx25', 'rsi25', 'willR25', 'cci25', 'volume_obv', 'volume_vwap', 'volatility_bbh', 'volatility_bbl', 'volatility_bbp', 'volatility_kcc', 'volatility_kch', 'volatility_kcl', 'volatility_dcl', 'volatility_dch', 'volatility_dcm', 'volatility_dcp', 'trend_macd_signal', 'trend_vortex_ind_diff', 'trend_kst_sig', 'trend_ichimoku_conv', 'trend_ichimoku_base', 'trend_ichimoku_a', 'trend_ichimoku_b', 'trend_visual_ichimoku_a', 'trend_visual_ichimoku_b', 'momentum_stoch', 'momentum_ao', 'momentum_ppo_signal', 'momentum_kama', 'alpha6', 'alpha51']\n",
      "dropped: ['tb_quote_av', 'sma5', 'ema8', 'sma8', 'ema12', 'sma12', 'ema16', 'sma16', 'ema20', 'sma20', 'ema26', 'sma26', 'rsi10', 'rsi14', 'adx17', 'rsi17', 'willR17', 'cci17', 'adx20', 'rsi20', 'stochrsi20', 'willR20', 'cci20', 'adx25', 'rsi25', 'willR25', 'cci25', 'volume_obv', 'volume_vwap', 'volatility_bbh', 'volatility_bbl', 'volatility_bbp', 'volatility_kcc', 'volatility_kch', 'volatility_kcl', 'volatility_dcl', 'volatility_dch', 'volatility_dcm', 'volatility_dcp', 'trend_macd_signal', 'trend_vortex_ind_diff', 'trend_kst_sig', 'trend_ichimoku_conv', 'trend_ichimoku_base', 'trend_ichimoku_a', 'trend_ichimoku_b', 'trend_visual_ichimoku_a', 'trend_visual_ichimoku_b', 'momentum_stoch', 'momentum_ao', 'momentum_ppo_signal', 'momentum_kama', 'others_cr', 'alpha6', 'alpha51']\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'to_pickle'",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  Cell \u001b[0;32mIn[14], line 1\u001b[0m\n    preprocess_data(tickers)\u001b[0m\n",
      "\u001b[1;36m  Cell \u001b[1;32mIn[12], line 12\u001b[1;36m in \u001b[1;35mpreprocess_data\u001b[1;36m\n\u001b[1;33m    renders[name].to_pickle(f'{name}_renders_{\"_\".join(tickers)}.pickle')\u001b[1;36m\n",
      "\u001b[1;31mAttributeError\u001b[0m\u001b[1;31m:\u001b[0m 'list' object has no attribute 'to_pickle'\n"
     ]
    }
   ],
   "source": [
    "preprocess_data(tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5eb96ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BTCUSDTETHUSDTSOLUSDT'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd37253",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_env(cfg):\n",
    "    tickers = [\"BTCUSDT\",\"ETHUSDT\",\"SOLUSDT\"]\n",
    "    env_data = load_ticker_data(tickers)\n",
    "    cleaned_data = clean_data(env_data)\n",
    "    X_train_list, X_test_list, X_valid_list, y_train_list, y_test_list, y_valid_list = split_data(cleaned_data)\n",
    "    renders, features = separate_render_features(X_test_list, tickers)\n",
    "    price_streams = get_price_stream(renders, tickers)\n",
    "    binance = Exchange('binance', service=execute_order)(*price_streams)\n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f770d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://github.com/tensortrade-org/tensortrade/blob/master/examples/train_and_evaluate.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0e76fa02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `pca` not found.\n"
     ]
    }
   ],
   "source": [
    "utiliser le scaler des train data seulement pr le test, et si perf sont meilleures avec minmax (tester aussi sur timesnet -) et tester pca?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f955ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.tensortrade.org/en/latest/examples/setup_environment_tutorial.html\n",
    "#https://github.com/tensortrade-org/tensortrade/blob/master/examples/train_and_evaluate.ipynb\n",
    "https://levelup.gitconnected.com/portfolio-allocation-with-tensortrade-part-2-2-9ac30a6bcbfe\n",
    "https://www.tensortrade.org/en/latest/agents/overview.html#stable-baselines\n",
    "https://levelup.gitconnected.com/portfolio-allocation-with-tensortrade-part-2-2-9ac30a6bcbfe\n",
    "    https://github.com/Tomas0413/tensortrade-experiments/blob/main/TensorTrade%20-%20Sinewave%20with%20SimpleProfit%20and%20ManagedRiskOrders.ipynb\n",
    "    https://www.google.com/search?q=feature_engine&sourceid=chrome&ie=UTF-8\n",
    "        https://github.com/tensortrade-org/tensortrade/blob/master/examples/train_and_evaluate.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
